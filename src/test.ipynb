{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from rarity_score import *\n",
    "from torchvision import datasets, transforms, models\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "seed = 2302\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "transform_inception = transforms.Compose([\n",
    "    transforms.Resize((299, 299)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# transform_resnet = transforms.Compose([\n",
    "#     transforms.Resize((224, 224)),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "# ])\n",
    "\n",
    "\n",
    "# load datasets\n",
    "# wider_dataset = datasets.WIDERFace(\"./widerface_data\", split =\"train\", download=True, transform = transform_inception)\n",
    "pet_dataset = datasets.OxfordIIITPet(root=\"./oxford_pet_data/\", split=\"trainval\", download=True, transform=transform_inception)\n",
    "\n",
    "\n",
    "\n",
    "# load inception v3 feature extractor\n",
    "inception = models.inception_v3(pretrained=True).to(device)\n",
    "# resnet = models.resnet50(pretrained=True).to(device)\n",
    "\n",
    "pet_loader = DataLoader(pet_dataset, batch_size=64, shuffle=True)\n",
    "# wider_loader = DataLoader(wider_dataset, batch_size=64)\n",
    "\n",
    "\n",
    "def extract_features_and_split(model, data_loader, fake_ratio=0.3):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    real_features_list = []\n",
    "    fake_features_list = []\n",
    "    total_batches = len(data_loader)\n",
    "    fake_batches = int(total_batches * fake_ratio)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(tqdm(data_loader)):\n",
    "            images = batch[0].to(device)\n",
    "            output = model(images)\n",
    "\n",
    "            if i < fake_batches:\n",
    "                fake_features_list.append(output.cpu())  # Add to fake list\n",
    "            else:\n",
    "                real_features_list.append(output.cpu())  # Add to real list\n",
    "\n",
    "    # Concatenate all feature tensors to form single tensors for real and fake\n",
    "    real_features = torch.cat(real_features_list, dim=0)\n",
    "    fake_features = torch.cat(fake_features_list, dim=0)\n",
    "    \n",
    "    return real_features, fake_features\n",
    "\n",
    "# Example usage\n",
    "real_pet_features, fake_pet_features = extract_features_and_split(inception, pet_loader)\n",
    "\n",
    "# wider_features = extract_features(inception, wider_loader)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
